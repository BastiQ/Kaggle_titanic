# Kaggle Titanic Challenge
My try on the famous Titanic challenge from Kaggle. As a first Step I explored and analysed the given Dataset (see Feature Engineering notebook). Afterwards, I did a principle component analysis to extract useful features. As a last step I used a support vector machine with radial basis function as a kernel to predict who will die and who will survive on the Titanic. I scored 0.74641 on Kaggle which is pretty decent for the time that I've invested. This could be optimized by advanced methods of feature engineering like finding families from names for example. After my Submission I looked at some of the solutions on the Kaggle Site and found that a dacision tree or even better a Random Forest might have produced better results. 
